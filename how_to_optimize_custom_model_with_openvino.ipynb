{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.サンプル学習データのダウンロード\n",
    "37種類の犬と猫の画像です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://hiouchiystorage.blob.core.windows.net/share/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mv data.zip train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip train_data/data.zip -d train_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.モデルの学習（ResNet50を転移学習）\n",
    "TensorFlow v2.xのPre trainedモデルのResNet50をベースに、37種類の犬と猫を分類するカスタムモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "from tensorflow.keras import optimizers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_path = 'train_data/test/'\n",
    "train_path = 'train_data/train/'\n",
    "val_path = 'train_data/val/'\n",
    "WIDTH=224\n",
    "HEIGHT=224\n",
    "BATCH_SIZE=64\n",
    "\n",
    "#Train DataSet Generator with Augmentation\n",
    "print(\"\\nTraining Data Set\")\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_flow = train_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Validation DataSet Generator with Augmentation\n",
    "print(\"\\nValidation Data Set\")\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_flow = val_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Test DataSet Generator with Augmentation\n",
    "print(\"\\nTest Data Set\")\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_flow = test_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize MobileNet with transfer learning\n",
    "base_model = applications.ResNet50(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(WIDTH, HEIGHT,3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# and a dense layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_flow.class_indices), activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional MobileNet layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "import math\n",
    "top_layers_file_path=\"mobilenet.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('./logs/mn-log.csv', append=True)\n",
    "\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=1, \n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])\n",
    "\n",
    "\n",
    "model.load_weights(top_layers_file_path)\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)\n",
    "\n",
    "\n",
    "label = [k for k,v in train_flow.class_indices.items()]\n",
    "with open('labels.txt', 'w+') as file:\n",
    "    file.write(\"\\n\".join(label))\n",
    " \n",
    "tf.saved_model.save(model, 'resnet50_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.モデルの推論\n",
    "そのままTensorFlow上で推論を実行し、性能を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import argparse\n",
    "import sys\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inference_on_tf(numOfImages=50):\n",
    "    loaded = tf.saved_model.load('resnet50_model')\n",
    "    #print(list(loaded.signatures.keys()))  # [\"serving_default\"]\n",
    "\n",
    "    infer = loaded.signatures[\"serving_default\"]\n",
    "    output_node_name = next(iter(infer.structured_outputs.keys()))\n",
    "\n",
    "    #Read in Labels\n",
    "    arg_labels=\"labels.txt\"\n",
    "    label_file = open(arg_labels, \"r\")\n",
    "    labels = label_file.read().split('\\n')\n",
    "\n",
    "    file_list = glob.glob(\"train_data/test/*/*\")\n",
    "    for i in range(100):\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "\n",
    "        start1 = time.time()\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=[224, 224])\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        x = tf.keras.applications.mobilenet.preprocess_input(x[tf.newaxis,...])\n",
    "\n",
    "        start2 = time.time() #ここ追加\n",
    "        labeling = infer(tf.constant(x))[output_node_name]\n",
    "        infer_time = time.time() - start2\n",
    "        total_time = time.time() - start1\n",
    "        print(\"Filename:{}, Prediction:{}, ProcTime:{}, InferTime:{}\".format(img_path, labels[np.argsort(labeling)[0,::-1][0]], int(total_time*1000), int(infer_time*1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_on_tf(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ここから量子化↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Intel® Low Precision Optimization Tool（iLit）をインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install ilit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.モデルの入力Op、および、出力Opの名称を確認\n",
    "モデル（pb）の入出力レイヤ名を[Netron](https://lutzroeder.github.io/netron/)を使って取得します。ちなみに、今回のResNet50に場合は、入力が\"input\"で、出力が\"predict\"です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.iLitにて量子化実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iLitはあくまでもプログラミングライブラリです。従って、iLitが提供するAPIを使用して量子化を実行するためのアプリケーションを開発する必要があります。ただ、それも面倒な作業なので[iLitのGithub](https://github.com/intel/lp-opt-tool)にはサンプルコードとして、iLitのAPIを使用した量子化アプリが用意されています。以下は、その量子化アプリを利用した量子化の実行コマンドです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行中に各パラメータの意味を確認しましょう。\n",
    "\n",
    "- --input-graph ./resnet50_fp32_pretrained_model.pb ・・・入力元のFP32のモデルファイルのパス\n",
    "- --input input ・・・モデルの入力Opの名前\n",
    "- --output predict ・・・モデルの出力Opの名前\n",
    "- --output-graph ./resnet50_int8_pretrained_model.pb ・・・出力先のINT8のモデルファイルのパス\n",
    "- --data-location /imagenet/tfrecord/ ・・・量子化用画像データのパス\n",
    "- --image_size 224 ・・・画像データのサイズ\n",
    "- --resize_method crop ・・・画像前処理としてリサイズする際の方法。デフォルトがCrop。\n",
    "- --batch-size 10 ・・・バッチサイズ\n",
    "- --config resnet50_v1.yaml ・・・量子化用の設定ファイル\n",
    "- --tune ・・・iLitによるチューニングを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "量子化用の設定ファイル（YAML）の中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat resnet50_v1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.量子化後のTensorFlowモデルを実行して性能比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、量子化後のTensorFlowモデルを実行します。先ほどと同じ推論スクリプトを使用します。\n",
    "\n",
    "Intel TensorFlowをご使用いただいていれば、アプリケーションコードを変更しなくても、INT8のモデルを自動検知し、適切なCPU命令セット（Intel VNNI等）を実行します。推論処理のスピードがどの程度向上したかをご確認下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_on_tf(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowでの作業は以上となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ここからOpenVINO↓\n",
    "# 8.OpenVINOでFP32モデルをCPUに最適化（IRに変換）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからはIntel® OpenVINO™ Toolkitを用いた量子化方法をご紹介します。\n",
    "\n",
    "といってもまずは、元のTensorFlowのモデル（FP32）をOpenVINOのIR（Intermidiate Repretation）形式に変換するところから実施しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --saved_model_dir ./mobilenet --input_shape=[1,224,224,3] --data_type FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IR(xml+bin)が生成されていることを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.最適化済みのモデル(IR)をOpenVINOの推論エンジン（Inference Engine）上で実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRをOpenVINOの推論エンジン（IE）上で実行してみます。モデルはFP32のままですが、IRに変換することでモデルの内部構造がCPUに最適化され、大きく性能が向上したことが確認できるかと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import argparse\n",
    "import sys\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.labels = []\n",
    "        labels_filename = \"labels.txt\"\n",
    "        #Read in Labels\n",
    "        arg_labels=\"labels.txt\"\n",
    "        label_file = open(arg_labels, \"r\")\n",
    "        self.labels = label_file.read().split('\\n')\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def convert_to_opencv(self, image):\n",
    "        # RGB -> BGR conversion is performed as well.\n",
    "        image = image.convert('RGB')\n",
    "        r,g,b = np.array(image).T\n",
    "        opencv_image = np.array([b,g,r]).transpose()\n",
    "        return opencv_image\n",
    "\n",
    "    def crop_center(self, img,cropx,cropy):\n",
    "        h, w = img.shape[:2]\n",
    "        startx = w//2-(cropx//2)\n",
    "        starty = h//2-(cropy//2)\n",
    "        return img[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "    def resize_down_to_1600_max_dim(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if (h < 1600 and w < 1600):\n",
    "            return image\n",
    "\n",
    "        new_size = (1600 * w // h, 1600) if (h > w) else (1600, 1600 * h // w)\n",
    "        return cv2.resize(image, new_size, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    def resize_to_256_square(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        return cv2.resize(image, (256, 256), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    def update_orientation(self, image):\n",
    "        exif_orientation_tag = 0x0112\n",
    "        if hasattr(image, '_getexif'):\n",
    "            exif = image._getexif()\n",
    "            if (exif != None and exif_orientation_tag in exif):\n",
    "                orientation = exif.get(exif_orientation_tag, 1)\n",
    "                # orientation is 1 based, shift to zero based and flip/transpose based on 0-based values\n",
    "                orientation -= 1\n",
    "                if orientation >= 4:\n",
    "                    image = image.transpose(Image.TRANSPOSE)\n",
    "                if orientation == 2 or orientation == 3 or orientation == 6 or orientation == 7:\n",
    "                    image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                if orientation == 1 or orientation == 2 or orientation == 5 or orientation == 6:\n",
    "                    image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return image\n",
    "\n",
    "class OpenVINOModel(Model):\n",
    "\n",
    "    def __init__(self, target_device, modelFilePath):\n",
    "        super(OpenVINOModel, self).__init__()\n",
    "\n",
    "        # These are set to the default names from exported models, update as needed.\n",
    "        model_xml = modelFilePath\n",
    "        model_bin = modelFilePath.replace('.xml', '.bin')\n",
    "\n",
    "        # Plugin initialization for specified device and load extensions library if specified\n",
    "        # Set the desired device name as 'device' parameter. This sample support these 3 names: CPU, GPU, MYRIAD\n",
    "        ie = IECore()\n",
    "\n",
    "        # Read IR\n",
    "        self.net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "\n",
    "        self.input_blob = next(iter(self.net.inputs))\n",
    "        self.out_blob = next(iter(self.net.outputs))\n",
    "        self.net.batch_size = 1\n",
    "\n",
    "        # Loading model to the plugin\n",
    "        self.exec_net = ie.load_network(network=self.net, device_name='CPU', num_requests=1)\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        start1 = time.time() #ここ追加\n",
    "\n",
    "        # Load from a file\n",
    "        image = Image.open(imageFile)\n",
    "\n",
    "        # Update orientation based on EXIF tags, if the file has orientation info.\n",
    "        image = super().update_orientation(image)\n",
    "\n",
    "        # Convert to OpenCV format\n",
    "        image = super().convert_to_opencv(image)\n",
    "\n",
    "        # If the image has either w or h greater than 1600 we resize it down respecting\n",
    "        # aspect ratio such that the largest dimension is 1600\n",
    "        image = super().resize_down_to_1600_max_dim(image)\n",
    "\n",
    "        # We next get the largest center square\n",
    "        h, w = image.shape[:2]\n",
    "        min_dim = min(w,h)\n",
    "        max_square_image = super().crop_center(image, min_dim, min_dim)\n",
    "\n",
    "        # Resize that square down to 256x256\n",
    "        augmented_image = super().resize_to_256_square(max_square_image)\n",
    "\n",
    "        # Get the input size of the model\n",
    "        n, c, h, w = self.net.inputs[self.input_blob].shape\n",
    "\n",
    "        # Crop the center for the specified network_input_Size\n",
    "        augmented_image = super().crop_center(augmented_image, w, h)\n",
    "        frame = augmented_image\n",
    "\n",
    "        #\n",
    "        augmented_image = augmented_image.transpose((2, 0, 1))\n",
    "\n",
    "        images = np.ndarray(shape=(n, c, h, w))\n",
    "        images[0] = augmented_image\n",
    "\n",
    "        start2 = time.time() #ここ追加\n",
    "        predictions = self.exec_net.infer(inputs={self.input_blob: images})\n",
    "        infer_time = time.time() - start2\n",
    "\n",
    "        # Print the highest probability label\n",
    "        predictions = predictions[self.out_blob]\n",
    "        highest_probability_index = predictions[0].argsort()[-1:][::-1][0]\n",
    "\n",
    "        total_time = time.time() - start1\n",
    "\n",
    "        #return total_time, infer_time, self.labels[highest_probability_index], frame  #ここ追加\n",
    "        return total_time, infer_time, \"\", frame  #ここ追加\n",
    "\n",
    "\n",
    "def run_inference(modelFile, model_type=\"tf\", target_device='CPU', total=500):\n",
    "    if model_type == 'tf':\n",
    "        model = TFModel(modelFile)\n",
    "    elif model_type == 'tf_int8':\n",
    "        model = TFModel(modelFile)\n",
    "    else:\n",
    "        if target_device == 'GPU':\n",
    "            model = OpenVINOModel('GPU', modelFile)\n",
    "        elif target_device == 'MYRIAD':\n",
    "            model = OpenVINOModel('MYRIAD', modelFile)\n",
    "        else:\n",
    "            model = OpenVINOModel('CPU', modelFile)\n",
    "\n",
    "    total_infer_spent_time = 0\n",
    "    total_spent_time = 0\n",
    "    list_df = pd.DataFrame( columns=['正解ラベル','予測ラベル','全処理時間(msec)','推論時間(msec)'] )\n",
    "\n",
    "    match = 0\n",
    "    #file_list = glob.glob(os.path.join(dataset_dir, \"*\"))\n",
    "    file_list = glob.glob(\"train_data/test/*/*\")\n",
    "    for i in range(total):\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "        total_time, infer_time, pred_label, frame = model.predict(img_path)\n",
    "\n",
    "        if i > 1:\n",
    "            total_infer_spent_time += infer_time\n",
    "            total_spent_time += total_time\n",
    "\n",
    "        if img_cat == pred_label:\n",
    "            match = match + 1\n",
    "\n",
    "        print(img_path, str(int(total_time*1000.0)) + 'msec', str(int(infer_time*1000.0)) + 'msec', pred_label) #ここ追加\n",
    "\n",
    "        tmp_se = pd.Series( [img_cat, pred_label, str(int(total_time * 1000)), str(int(infer_time * 1000)) ], index=list_df.columns )\n",
    "        list_df = list_df.append( tmp_se, ignore_index=True ) \n",
    "\n",
    "    print()\n",
    "    print('全' + str(total) + '枚 完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / (total-1))*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / (total-1))*1000.0)) + \" ms/枚\")\n",
    "    print(\"正解率: \" + str(match / total * 100.0))\n",
    "    return int((total_spent_time / (total-1))*1000.0), int((total_infer_spent_time / (total-1))*1000.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_total_time, tf_infer_time = run_inference('saved_model.xml', model_type='openvino', total=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ここからOpenVINOで量子化↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.OpenVINOのPOTでIRを量子化\n",
    "IRの量子化はOpenVINOのPOT（Post-Training Optimization Toolkit）を使用して行います。事前にPOTの[セットアップ](https://docs.openvinotoolkit.org/latest/_README.html#install_post_training_optimization_toolkit)を完了させて下さい。\n",
    "\n",
    "その後、量子化のための各種設定を記述したConfigファイル（JSON）を準備（ダウンロード）します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hiouchiy/IntelAI/master/tensorflow_quantization/resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に今回使用するConfigファイルの中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでPOTに関して2点補足説明です。\n",
    "\n",
    "1. POTはAccuracyCheckerという既存ツールを前提としている\n",
    "\n",
    "    AccuracyCheckerはその名の通り、モデルのAccuracyを計測するためのツールです。OpenVINOのIRに変換後のモデルはもちろん、変換前の形式（TensorFlow、PyTorch、ONNXなど）であっても実行可能です。POTはこのAccuracyCheckrを拡張した機能であるため、AccuracyCheckrへの依存関係があります。したがって、上記Configファイルの前半部分は、まさにAccuracyChecker用の設定になります。\n",
    "より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_README.html)を参照ください。\n",
    "\n",
    "\n",
    "2. POTには2つの量子化のアルゴリズムが用意されている\n",
    "\n",
    "    量子化のアルゴリズムとして下記2つのいずれかを利用可能です。より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_README.html)\n",
    "    - DefaultQuantization・・・このサンプルで利用。より量子化処理の実行時間を高速化を優先。より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_default_README.html)\n",
    "    - AccuracyAwareQuantization・・・より量子化後のAccuracyを優先。時間がかかることがある。より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_accuracy_aware_README.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、POTを使って量子化を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pot -c resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行が成功すると、resultsというフォルダが作成されます。そして、量子化済みのIRがその中に格納されています。\n",
    "\n",
    "results/se_resnet50_DefaultQuantization/日付日時のフォルダ/optimized/**.xml\n",
    "\n",
    "ちなみに、POTコマンドではなく、[Pythonスクリプト](https://docs.openvinotoolkit.org/latest/_sample_README.html#how_to_run_the_sample)を書いて同様のことを実現可能することも可能です。より細かなカスタマイズを行いたい時などはぜひご利用ください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.量子化後のIRを実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記コマンドの日時の部分（2020-10-07_12-55-36）を実際のものに書き換えてから実行ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_total_time, tf_infer_time = run_inference('results/mobilenet_int8_DefaultQuantization/2020-12-02_05-19-03/optimized/mobilenet_int8.xml', model_type='openvino', total=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# おしまい！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
