{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.サンプル学習データのダウンロード\n",
    "37種類の犬と猫の画像です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://hiouchiystorage.blob.core.windows.net/share/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mv data.zip train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip train_data/data.zip -d train_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.モデルの学習（ResNet50を転移学習）\n",
    "TensorFlow v2.xのPre trainedモデルのResNet50をベースに、37種類の犬と猫を分類するカスタムモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "from tensorflow.keras import optimizers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_path = 'train_data/test/'\n",
    "train_path = 'train_data/train/'\n",
    "val_path = 'train_data/val/'\n",
    "WIDTH=224\n",
    "HEIGHT=224\n",
    "BATCH_SIZE=64\n",
    "\n",
    "#Train DataSet Generator with Augmentation\n",
    "print(\"\\nTraining Data Set\")\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_flow = train_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Validation DataSet Generator with Augmentation\n",
    "print(\"\\nValidation Data Set\")\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_flow = val_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Test DataSet Generator with Augmentation\n",
    "print(\"\\nTest Data Set\")\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_flow = test_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize MobileNet with transfer learning\n",
    "base_model = applications.ResNet50(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(WIDTH, HEIGHT,3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# and a dense layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_flow.class_indices), activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional MobileNet layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "import math\n",
    "top_layers_file_path=\"resnet50.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('./logs/mn-log.csv', append=True)\n",
    "\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=1, \n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])\n",
    "\n",
    "\n",
    "model.load_weights(top_layers_file_path)\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)\n",
    "\n",
    "\n",
    "label = [k for k,v in train_flow.class_indices.items()]\n",
    "with open('labels.txt', 'w+') as file:\n",
    "    file.write(\"\\n\".join(label))\n",
    " \n",
    "tf.saved_model.save(model, 'resnet50_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングには時間がかかるので、待てないという方はこちらからトレーニング済みのモデルファイルをダウンロードください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://hiouchiystorage.blob.core.windows.net/share/resnet50_model.zip; unzip resnet50_model.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## おまけ①　上記ダウンロードしたモデルを追加学習するためのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_path = 'train_data/test/'\n",
    "train_path = 'train_data/train/'\n",
    "val_path = 'train_data/val/'\n",
    "WIDTH=224\n",
    "HEIGHT=224\n",
    "BATCH_SIZE=64\n",
    "\n",
    "#Train DataSet Generator with Augmentation\n",
    "print(\"\\nTraining Data Set\")\n",
    "train_generator = ImageDataGenerator()\n",
    "train_flow = train_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Validation DataSet Generator with Augmentation\n",
    "print(\"\\nValidation Data Set\")\n",
    "val_generator = ImageDataGenerator()\n",
    "val_flow = val_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Test DataSet Generator with Augmentation\n",
    "print(\"\\nTest Data Set\")\n",
    "test_generator = ImageDataGenerator()\n",
    "test_flow = test_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "new_model = tf.keras.models.load_model('resnet50_model')    \n",
    "model = new_model\n",
    "model.summary()\n",
    "\n",
    "import math\n",
    "top_layers_file_path=\"resnet50.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('./logs/mn-log.csv', append=True)\n",
    "\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=1, \n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])\n",
    "\n",
    "\n",
    "model.load_weights(top_layers_file_path)\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)\n",
    "\n",
    "\n",
    "label = [k for k,v in train_flow.class_indices.items()]\n",
    "with open('labels.txt', 'w+') as file:\n",
    "    file.write(\"\\n\".join(label))\n",
    " \n",
    "tf.saved_model.save(model, 'resnet50_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## おまけ② モデルをFrozen Graphにすることもできます。（※今回はSavedModel形式で保存しています。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert Keras model to ConcreteFunction\n",
    "full_model = tf.function(lambda x: model(x))\n",
    "concrete_function = full_model.get_concrete_function(\n",
    "    x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_model = convert_variables_to_constants_v2(concrete_function)\n",
    "\n",
    "# Generate frozen pb\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_model.graph,\n",
    "                   logdir=\"./frozen_models\",\n",
    "                   name=\"simple_frozen_graph.pb\",\n",
    "                   as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.モデルの推論\n",
    "そのままTensorFlow上で推論を実行し、性能を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import argparse\n",
    "import sys\n",
    "from openvino.inference_engine import IECore\n",
    "import IPython.display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inference_on_tf(numOfImages=50):\n",
    "    loaded = tf.saved_model.load('resnet50_model')\n",
    "    #print(list(loaded.signatures.keys()))  # [\"serving_default\"]\n",
    "\n",
    "    infer = loaded.signatures[\"serving_default\"]\n",
    "    output_node_name = next(iter(infer.structured_outputs.keys()))\n",
    "\n",
    "    #Read in Labels\n",
    "    arg_labels=\"train_data/labels.txt\"\n",
    "    label_file = open(arg_labels, \"r\")\n",
    "    labels = label_file.read().split('\\n')\n",
    "\n",
    "    total_spent_time = 0\n",
    "    total_infer_spent_time = 0\n",
    "    file_list = glob.glob(\"train_data/test/*/*\")\n",
    "    for i in range(numOfImages):\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "\n",
    "        start1 = time.time()\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=[224, 224])\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        x = tf.keras.applications.resnet.preprocess_input(x[tf.newaxis,...])\n",
    "\n",
    "        start2 = time.time() #ここ追加\n",
    "        labeling = infer(tf.constant(x))[output_node_name]\n",
    "        infer_time = time.time() - start2\n",
    "        \n",
    "        label_index = np.argsort(labeling)[0,::-1][0]\n",
    "        pred_label = labels[label_index]\n",
    "        total_time = time.time() - start1\n",
    "        \n",
    "        if i > 1:\n",
    "            total_infer_spent_time += infer_time\n",
    "            total_spent_time += total_time\n",
    "        \n",
    "        #print(\"Filename:{}, Prediction:{}, ProcTime:{}, InferTime:{}\".format(img_path, pred_label, int(total_time*1000), int(infer_time*1000)))\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        frame = cv2.imread(img_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        if frame.shape[:-1] != (224, 224):\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "        cv2.putText(frame,'No ' + str(i+1) + ':' + str(int(total_time*1000)) + ',' + str(int(infer_time*1000)), (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame,'No ' + str(i+1) + ':' + str(int(total_time*1000)) + ',' + str(int(infer_time*1000)), (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.putText(frame,str(img_cat), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame,str(img_cat), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.putText(frame,str(pred_label), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame,str(pred_label), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(frame).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "        \n",
    "    print()\n",
    "    print('全' + str(numOfImages) + '枚 完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / (numOfImages-1))*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / (numOfImages-1))*1000.0)) + \" ms/枚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_on_tf(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowでの作業は以上となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ここからOpenVINO↓\n",
    "# 4.OpenVINOでFP32モデルをCPUに最適化（IRに変換）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからはIntel® OpenVINO™ Toolkitを用いた量子化方法をご紹介します。\n",
    "\n",
    "といってもまずは、元のTensorFlowのモデル（FP32）をOpenVINOのIR（Intermidiate Repretation）形式に変換するところから実施しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --saved_model_dir ./resnet50_model --input_shape=[1,224,224,3] --data_type FP32 --model_name resnet50_fp32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IR(xml+bin)が生成されていることを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.最適化済みのモデル(IR)をOpenVINOの推論エンジン（Inference Engine）上で実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRをOpenVINOの推論エンジン（IE）上で実行してみます。モデルはFP32のままですが、IRに変換することでモデルの内部構造がCPUに最適化され、大きく性能が向上したことが確認できるかと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import argparse\n",
    "import sys\n",
    "from openvino.inference_engine import IECore\n",
    "import IPython.display\n",
    "from IPython.display import clear_output \n",
    "from tensorflow.keras.applications.resnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        #Read in Labels\n",
    "        arg_labels=\"train_data/labels.txt\"\n",
    "        label_file = open(arg_labels, \"r\")\n",
    "        self.labels = label_file.read().split('\\n')\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class OpenVINOModel(Model):\n",
    "\n",
    "    def __init__(self, target_device, modelFilePath):\n",
    "        super(OpenVINOModel, self).__init__()\n",
    "\n",
    "        # These are set to the default names from exported models, update as needed.\n",
    "        model_xml = modelFilePath\n",
    "        model_bin = modelFilePath.replace('.xml', '.bin')\n",
    "\n",
    "        # Plugin initialization for specified device and load extensions library if specified\n",
    "        # Set the desired device name as 'device' parameter. This sample support these 3 names: CPU, GPU, MYRIAD\n",
    "        ie = IECore()\n",
    "\n",
    "        # Read IR\n",
    "        self.net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "\n",
    "        self.input_blob = next(iter(self.net.inputs))\n",
    "        self.out_blob = next(iter(self.net.outputs))\n",
    "        self.net.batch_size = 1\n",
    "\n",
    "        # Loading model to the plugin\n",
    "        self.exec_net = ie.load_network(network=self.net, device_name='CPU', num_requests=1)\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        start1 = time.time() #ここ追加\n",
    "        \n",
    "        image = cv2.imread(imageFile)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if image.shape[:-1] != (224, 224):\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "        frame = image\n",
    "        image = preprocess_input(image)\n",
    "        image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "        image = image.reshape((1, 3, 224, 224))\n",
    "        images = image\n",
    "        \n",
    "\n",
    "        start2 = time.time() #ここ追加\n",
    "        predictions = self.exec_net.infer(inputs={self.input_blob: images})\n",
    "        infer_time = time.time() - start2\n",
    "\n",
    "        # Print the highest probability label\n",
    "        predictions = predictions[self.out_blob]\n",
    "        highest_probability_index = predictions[0].argsort()[-1:][::-1][0]\n",
    "\n",
    "        total_time = time.time() - start1\n",
    "\n",
    "        return total_time, infer_time, self.labels[highest_probability_index], frame  #ここ追加\n",
    "        #return total_time, infer_time, \"\", frame  #ここ追加\n",
    "\n",
    "\n",
    "def inference_on_ov(modelFile, model_type=\"tf\", target_device='CPU', total=500):\n",
    "    if model_type == 'tf':\n",
    "        model = TFModel(modelFile)\n",
    "    elif model_type == 'tf_int8':\n",
    "        model = TFModel(modelFile)\n",
    "    else:\n",
    "        if target_device == 'GPU':\n",
    "            model = OpenVINOModel('GPU', modelFile)\n",
    "        elif target_device == 'MYRIAD':\n",
    "            model = OpenVINOModel('MYRIAD', modelFile)\n",
    "        else:\n",
    "            model = OpenVINOModel('CPU', modelFile)\n",
    "\n",
    "    total_infer_spent_time = 0\n",
    "    total_spent_time = 0\n",
    "    list_df = pd.DataFrame( columns=['正解ラベル','予測ラベル','全処理時間(msec)','推論時間(msec)'] )\n",
    "\n",
    "    match = 0\n",
    "    #file_list = glob.glob(os.path.join(dataset_dir, \"*\"))\n",
    "    file_list = glob.glob(\"train_data/test/*/*\")\n",
    "    for i in range(total):\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "        total_time, infer_time, pred_label, frame = model.predict(img_path)\n",
    "\n",
    "        if i > 1:\n",
    "            total_infer_spent_time += infer_time\n",
    "            total_spent_time += total_time\n",
    "\n",
    "        #print(img_path, str(int(total_time*1000.0)) + 'msec', str(int(infer_time*1000.0)) + 'msec', pred_label) #ここ追加\n",
    "        clear_output(wait=True)\n",
    "        frame = cv2.imread(img_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        if frame.shape[:-1] != (224, 224):\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "        cv2.putText(frame,'No ' + str(i+1) + ':' + str(int(total_time*1000)) + ',' + str(int(infer_time*1000)), (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame,'No ' + str(i+1) + ':' + str(int(total_time*1000)) + ',' + str(int(infer_time*1000)), (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.putText(frame,str(img_cat), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame,str(img_cat), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.putText(frame,str(pred_label), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame,str(pred_label), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(frame).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "        tmp_se = pd.Series( [img_cat, pred_label, str(int(total_time * 1000)), str(int(infer_time * 1000)) ], index=list_df.columns )\n",
    "        list_df = list_df.append( tmp_se, ignore_index=True ) \n",
    "\n",
    "    print()\n",
    "    print('全' + str(total) + '枚 完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / (total-1))*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / (total-1))*1000.0)) + \" ms/枚\")\n",
    "    return int((total_spent_time / (total-1))*1000.0), int((total_infer_spent_time / (total-1))*1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_on_ov('resnet50_fp32.xml', model_type='openvino', total=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ここからOpenVINOで量子化↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.OpenVINOのPOTでIRを量子化\n",
    "IRの量子化はOpenVINOのPOT（Post-Training Optimization Toolkit）を使用して行います。事前にPOTの[セットアップ](https://docs.openvinotoolkit.org/latest/_README.html#install_post_training_optimization_toolkit)を完了させて下さい。\n",
    "\n",
    "その後、量子化のための各種設定を記述したConfigファイル（JSON）を準備します。今回は既にレポジトリ内に用意されている'resnet50_int8.json'を使用します。今回使用するConfigファイルの中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでPOTに関して2点補足説明です。\n",
    "\n",
    "1. POTはAccuracyCheckerという既存ツールを前提としている\n",
    "\n",
    "    AccuracyCheckerはその名の通り、モデルのAccuracyを計測するためのツールです。OpenVINOのIRに変換後のモデルはもちろん、変換前の形式（TensorFlow、PyTorch、ONNXなど）であっても実行可能です。POTはこのAccuracyCheckrを拡張した機能であるため、AccuracyCheckrへの依存関係があります。したがって、上記Configファイルの前半部分は、まさにAccuracyChecker用の設定になります。\n",
    "より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_README.html)を参照ください。\n",
    "\n",
    "\n",
    "2. POTには2つの量子化のアルゴリズムが用意されている\n",
    "\n",
    "    量子化のアルゴリズムとして下記2つのいずれかを利用可能です。より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_README.html)\n",
    "    - DefaultQuantization・・・このサンプルで利用。より量子化処理の実行時間を高速化を優先。より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_default_README.html)\n",
    "    - AccuracyAwareQuantization・・・より量子化後のAccuracyを優先。時間がかかることがある。より詳しくは[こちら](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_accuracy_aware_README.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、POTを使って量子化を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pot -c resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行が成功すると、resultsというフォルダが作成されます。そして、量子化済みのIRがその中に格納されています。\n",
    "\n",
    "results/resnet50_int8_DefaultQuantization/日付日時のフォルダ/optimized/**.xml と **.bin\n",
    "\n",
    "ちなみに、POTコマンドではなく、[Pythonスクリプト](https://docs.openvinotoolkit.org/latest/_sample_README.html#how_to_run_the_sample)を書いて同様のことを実現可能することも可能です。より細かなカスタマイズを行いたい時などはぜひご利用ください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.量子化後のIRを実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記コマンドの日時の部分（2020-10-07_12-55-36）を実際のものに書き換えてから実行ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_on_ov('results/resnet50_int8_DefaultQuantization/2020-12-03_05-22-17/optimized/resnet50_int8.xml', model_type='openvino', total=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出来上がったモデルを共有フォルダに格納して終了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cp -r results/resnet50_int8_DefaultQuantization/2020-12-03_05-22-17/optimized/ /workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# おしまい！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
